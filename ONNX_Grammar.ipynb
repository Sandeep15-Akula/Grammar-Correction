{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ONNX_Grammar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "2ojbjdhw_YqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3lxV49VqjVK",
        "outputId": "d3ff4618-457d-4f32-b8ab-9ee1ca332c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fastT5"
      ],
      "metadata": {
        "id": "-YgEOUD6_VbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX Model Generation"
      ],
      "metadata": {
        "id": "gGRVsl7X-fO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFvLyooA3uIx"
      },
      "outputs": [],
      "source": [
        "from fastT5 import export_and_get_onnx_model, generate_onnx_representation, quantize\n",
        "from transformers import T5Config, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = \"prithivida/grammar_error_correcter_v1\"\n",
        "\n",
        "onnx_model_paths = generate_onnx_representation(trained_model)\n",
        "\n",
        "quant_onnx_paths = quantize(onnx_model_paths)\n",
        "\n",
        "tokenizer_onnx = AutoTokenizer.from_pretrained(trained_model)\n",
        "config = T5Config.from_pretrained(trained_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVhmwko34gkg",
        "outputId": "92fa3ac7-6874-415c-8e38-ee9a2cf084d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exporting to onnx... |################################| 3/3\n",
            "Quantizing... |################################| 3/3\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_onnx.save_pretrained('models/')\n",
        "config.save_pretrained('models/')"
      ],
      "metadata": {
        "id": "x83__Dhv4oZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E35K45JBj_B",
        "outputId": "87feaad7-519d-4b21-8588-79bed0ac454d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp -r models '/content/gdrive/My Drive/Grammar_Correction'"
      ],
      "metadata": {
        "id": "KVhqLsejBXXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX Runtime"
      ],
      "metadata": {
        "id": "g5geP8FA9WYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastT5 import get_onnx_model, get_onnx_runtime_sessions, OnnxT5\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "def correct(input):\n",
        "  trained_model_path = \"/content/drive/MyDrive/Grammar_Correction/models\"\n",
        "\n",
        "  encoder_path = trained_model_path+\"/grammar_error_correcter_v1-encoder-quantized.onnx\"\n",
        "  decoder_path = trained_model_path+\"/grammar_error_correcter_v1-decoder-quantized.onnx\"\n",
        "  init_decoder_path = trained_model_path+\"/grammar_error_correcter_v1-init-decoder-quantized.onnx\"\n",
        "\n",
        "  model_paths = encoder_path,decoder_path,init_decoder_path\n",
        "  model_sessions = get_onnx_runtime_sessions(model_paths)\n",
        "  model = OnnxT5(trained_model_path,model_sessions)\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(trained_model_path)\n",
        "\n",
        "  prompt = 'gec:' + input\n",
        "  token = tokenizer(prompt, return_tensors='pt')\n",
        "  tokens = model.generate(input_ids=token['input_ids'],\n",
        "               attention_mask=token['attention_mask'],\n",
        "               num_beams=2)\n",
        "\n",
        "  output = tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)\n",
        "  return output"
      ],
      "metadata": {
        "id": "8rHJBhUP4x3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(correct(\"I name is Sandeep\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu-yzonM8WUz",
        "outputId": "0d8da9b6-464f-4e0d-eb66-8ba049f6577e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is Sandeep.\n"
          ]
        }
      ]
    }
  ]
}